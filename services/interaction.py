# ====================================================================
#  File: services/interaction.py
# ====================================================================
import json
import logging
import asyncio
import re
import os
from pathlib import Path
from pydantic import BaseModel

from .emotion import EmotionService
from .multi_intent import MultiIntentService
from .translator import TranslatorService
from .llm_manager import LLMManager
from .tts import TTSService
from .mcp.tool_registry import ToolRegistry
from .mcp.tool_manager import MCPToolManager
from .memory import MemoryService
from utils.style_map import get_style_from_emotion

class InteractResponse(BaseModel):
    text: str
    emotion: str
    intent: str
    style: str
    audio_url: str

class InteractionService:
    def __init__(
        self,
        emotion_service: EmotionService,
        multi_intent_service: MultiIntentService,
        translator_service: TranslatorService,
        llm_service: LLMManager,
        tts_service: TTSService,
        tool_registry: ToolRegistry,
        memory_service: MemoryService = None,
        mcp_tool_manager: MCPToolManager = None,
        llm_target: str = "rp",
        prompt_dir: str = "./checkpoints/LunaLLM",
        logger: logging.Logger = None
    ):
        self.emotion_service = emotion_service
        self.multi_intent_service = multi_intent_service
        self.translator_service = translator_service
        self.llm_service = llm_service
        self.tts_service = tts_service
        self.tool_registry = tool_registry
        self.mcp_tool_manager = mcp_tool_manager
        self.memory_service = memory_service or MemoryService()
        self.llm_target = llm_target
        self.logger = logger
        
        self._mcp_tools_cache = None
        self._mcp_tools_cache_time = 0

        try:
            prompt_path = Path(prompt_dir)
            # API ëª¨ë“œì¼ ë•ŒëŠ” í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            if llm_service.get_mode() == "api":
                self.rp_prompt_template = (prompt_path / "prompt_Kurumi_kr.txt").read_text(encoding='utf-8')
                print("[L.U.N.A. InteractionService] API ëª¨ë“œ: í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸(prompt_Kurumi_kr.txt) ë¡œë”© ì™„ë£Œ.")
            else:
                self.rp_prompt_template = (prompt_path / "prompt_Kurumi.txt").read_text(encoding='utf-8')
                print("[L.U.N.A. InteractionService] ë¡œì»¬ ì„œë²„ ëª¨ë“œ: ì˜ë¬¸ í”„ë¡¬í”„íŠ¸(prompt_Kurumi.txt) ë¡œë”© ì™„ë£Œ.")
            
            self.trans_prompt_template = (prompt_path / "prompt_Translate.txt").read_text(encoding='utf-8')
        except Exception as e:
            print(f"[L.U.N.A. InteractionService] í”„ë¡¬í”„íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self.rp_prompt_template = "User: {user_input}\nAssistant:"
            self.trans_prompt_template = "Translate the following text to Korean."

    def _get_available_mcp_tools(self) -> list:
        """MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ (ìºì‹± ì ìš©)"""
        import time
        
        if not self.mcp_tool_manager:
            return []
        
        current_time = time.time()
        if self._mcp_tools_cache is not None and (current_time - self._mcp_tools_cache_time) < 30:
            return self._mcp_tools_cache
        
        try:
            mcp_tools = self.mcp_tool_manager.get_tool_list()
            self._mcp_tools_cache = mcp_tools if mcp_tools else []
            self._mcp_tools_cache_time = current_time
            return self._mcp_tools_cache
        except Exception as e:
            self.logger.warning(f"[L.U.N.A. InteractionService] ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _call_mcp_tool(self, server_id: str, tool_name: str, arguments: dict, timeout: float | None = None) -> str:
        if not self.mcp_tool_manager:
            raise Exception("MCP ë„êµ¬ ë§¤ë‹ˆì €ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if timeout is None:
            timeout = float(os.getenv("LUNA_TOOL_TIMEOUT", "15"))
        
        try:
            import time
            
            if not hasattr(self, '_event_loop'):
                try:
                    self._event_loop = asyncio.get_event_loop()
                    if self._event_loop.is_closed():
                        self._event_loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(self._event_loop)
                except RuntimeError:
                    self._event_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(self._event_loop)

            self.logger.debug(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ ìƒì„¸ ì •ë³´:")
            self.logger.debug(f"  - Server: {server_id}")
            self.logger.debug(f"  - Tool: {tool_name}")
            self.logger.debug(f"  - Arguments: {arguments}")
            self.logger.debug(f"  - Timeout: {timeout}s")
            
            tool_start = time.time()
            self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ ì‹œì‘: {server_id}/{tool_name}")

            coro = self.mcp_tool_manager.call_tool(server_id, tool_name, arguments, timeout=timeout)
            result = self._event_loop.run_until_complete(coro)
            
            tool_elapsed = time.time() - tool_start
            if tool_elapsed > timeout * 0.8:
                self.logger.warning(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ ì§€ì—° ì¤‘: {tool_elapsed:.2f}s / {timeout}s (80% ì´ˆê³¼)")
            else:
                self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ ì™„ë£Œ: {tool_elapsed:.2f}s")

            result_str = str(result)
            if isinstance(result, dict):
                import json
                result_str = json.dumps(result, ensure_ascii=False)
            
            log_result = result_str[:100] if len(result_str) > 100 else result_str
            self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ ì„±ê³µ: {server_id}/{tool_name}")
            self.logger.info(f"[L.U.N.A. InteractionService] ë°˜í™˜ê°’: {log_result}")
            return result_str
        except asyncio.TimeoutError:
            self.logger.error(f"[L.U.N.A. InteractionService] '{server_id}/{tool_name}' ë„êµ¬ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
            raise
        except Exception as e:
            self.logger.error(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨: {server_id}/{tool_name}: {e}", exc_info=True)
            raise
    
    def _extract_tool_calls_from_text(self, text: str) -> tuple[list, int]:
        """
        LLM í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ ë„êµ¬ í˜¸ì¶œ ì¶”ì¶œ
        í˜•ì‹: 'call:server_id/tool_name{...}'
        
        Returns:
            (tool_calls, last_tool_end_index) - ë„êµ¬ í˜¸ì¶œ ëª©ë¡ê³¼ ë§ˆì§€ë§‰ ë„êµ¬ í˜¸ì¶œì˜ ë ìœ„ì¹˜
        """
        tool_calls = []
        last_tool_end = 0
        
        # íŒ¨í„´: 'call:server_id/tool_name{...}'
        pattern = r"call:([a-zA-Z0-9_/:.\-]+)"
        matches = list(re.finditer(pattern, text))
        
        for i, match in enumerate(matches):
            tool_id = match.group(1)
            
            start_idx = match.end()
            text_after = text[start_idx:].lstrip()
            
            if text_after.startswith('{'):
                brace_count = 0
                json_end = 0
                for j, char in enumerate(text_after):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = j + 1
                            break
                
                if json_end > 0:
                    args_str = text_after[:json_end]
                    try:
                        args = json.loads(args_str)
                    except json.JSONDecodeError as e:
                        self.logger.warning(f"[L.U.N.A. MCP] JSON íŒŒì‹± ì‹¤íŒ¨: {args_str[:100]} ({e})")
                        args = {}
                    
                    tool_calls.append({
                        "id": f"tool_call_{i}",
                        "function": {
                            "name": tool_id,
                            "arguments": args
                        }
                    })
                    
                    lstrip_count = len(text[start_idx:]) - len(text_after)
                    last_tool_end = start_idx + lstrip_count + json_end
        
        return tool_calls, last_tool_end

    def _normalize(self, s: str) -> str:
        import re
        return re.sub(r'[^a-z0-9]', '', s.lower())

    # í´ë°±ìš© í•¨ìˆ˜
    def _detect_and_suggest_tool(self, user_input: str, mcp_tools: list) -> dict | None:
        user_lower = user_input.lower()
        
        play_keywords = ["í‹€ì–´", "ì¬ìƒ", "í”Œë ˆì´", "play", "ì¼œ", "ì¼œì¤˜", "ë“¤ì„ë˜", "ë“¤ìœ¼ë©´ì„œ"]
        music_context = ["ìœ íŠœë¸Œ", "ìŒì•…", "ë®¤ì§", "ê³¡", "ë…¸ë˜", "singer", "artist"]
        
        is_play_request = any(kw in user_lower for kw in play_keywords)
        is_music_context = any(kw in user_lower for kw in music_context)
        
        if is_play_request and is_music_context:
            track_name = self._extract_song_name(user_input)
            if track_name:
                for tool in mcp_tools:
                    tool_name = tool.get('function', {}).get('name', '').lower()
                    if 'playtrack' in tool_name or 'play' in tool_name:
                        self.logger.info(f"[L.U.N.A. InteractionService] í´ë°±: ìŒì•… ì¬ìƒ ê°ì§€")
                        return {
                            "id": "auto_tool_call_1",
                            "function": {
                                "name": tool.get('function', {}).get('name', ''),
                                "arguments": {"trackName": track_name}
                            }
                        }
        
        pause_keywords = ["ë©ˆì¶°", "ë©ˆì¶”", "ì •ì§€", "ì¤‘ì§€", "pause", "stop", "êº¼", "ë„"]
        if any(kw in user_lower for kw in pause_keywords) and is_music_context:
            for tool in mcp_tools:
                tool_name = tool.get('function', {}).get('name', '').lower()
                if 'pausetrack' in tool_name or 'pause' in tool_name:
                    self.logger.info(f"[L.U.N.A. InteractionService] í´ë°±: ìŒì•… ì¼ì‹œì •ì§€ ê°ì§€")
                    return {
                        "id": "auto_tool_call_2",
                        "function": {
                            "name": tool.get('function', {}).get('name', ''),
                            "arguments": {}
                        }
                    }
        
        return None
    
    def _extract_song_name(self, text: str) -> str:
        import re
        
        match = re.search(r'([a-zA-Z0-9ê°€-í£\s\-&]+?)\s*(?:í‹€ì–´|ì¬ìƒ|í”Œë ˆì´|play|ì¼œ|ë“¤ì„ë˜|listen)', text)
        if match:
            song = match.group(1).strip()
            if song:
                return song
        
        match = re.search(r'(?:ì—ì„œ|ë®¤ì§ì—ì„œ)\s+([a-zA-Z0-9ê°€-í£\s\-&]+)(?:í‹€ì–´|ì¬ìƒ|í”Œë ˆì´)', text)
        if match:
            song = match.group(1).strip()
            if song:
                return song
        
        words = text.split()
        if len(words) > 2:
            result = []
            for word in reversed(words):
                if any(kw in word.lower() for kw in ["í‹€ì–´", "ì¬ìƒ", "í”Œë ˆì´", "play", "ì¼œ"]):
                    break
                result.insert(0, word)
            
            if result:
                return " ".join(result).strip()
        
        return text

    def _resolve_server_and_tool(self, raw_name: str, tools: list = None) -> tuple[str, str]:
        if "/" in raw_name:
            s, t = raw_name.split("/", 1)
            return s.strip(), t.strip()

        if tools is None:
            try:
                tools = self._get_available_mcp_tools() or []
            except Exception:
                tools = []
        else:
            tools = tools or []

        raw_norm = self._normalize(raw_name)
        candidates: list[tuple[str, str]] = []

        for it in tools:
            func = it.get("function", {}) if isinstance(it, dict) else {}
            tool_name = str(func.get("name", "")).strip()
            server_id = str(it.get("server_id") or it.get("server") or "").strip()
            if not server_id or not tool_name:
                continue

            pair = (server_id, tool_name)
            sv_norm = self._normalize(server_id)
            tl_norm = self._normalize(tool_name)
            cat_norm = self._normalize(server_id + tool_name)

            if raw_norm == cat_norm:
                candidates.append(pair)
                continue
            if raw_norm == tl_norm:
                candidates.append(pair)
                continue
            if raw_norm.startswith(sv_norm) and raw_norm.endswith(tl_norm):
                candidates.append(pair)
                continue

        if len(candidates) == 1:
            return candidates[0]
        if len(candidates) > 1:
            def score(p: tuple[str, str]) -> int:
                return len(self._normalize(p[0] + p[1]))
            candidates.sort(key=score, reverse=True)
            return candidates[0]

        raise ValueError(f"Cannot resolve tool uniquely from name '{raw_name}'. Expected 'server/tool'.")

    def run(self, ko_input_text: str, use_tools: bool = False) -> InteractResponse:
        self.logger.info(f"[L.U.N.A. InteractionService] ì‚¬ìš©ì ì…ë ¥: {ko_input_text} (ë„êµ¬ ì‚¬ìš©: {use_tools})")
        
        if use_tools and self.mcp_tool_manager:
            mcp_tools = self._get_available_mcp_tools()
            if mcp_tools:
                self.logger.info(f"[L.U.N.A. InteractionService] ì—ì´ì „íŠ¸ ëª¨ë“œ í™œì„±í™” - MCP ë„êµ¬ {len(mcp_tools)}ê°œ")
                return self._run_agent_mode(ko_input_text)
        
        self.logger.info("[L.U.N.A. InteractionService] ì¼ë°˜ ëª¨ë“œ ì²˜ë¦¬")
        return self._run_normal_mode(ko_input_text)
        
    def _run_agent_mode(self, ko_input_text: str) -> InteractResponse:
        import time
        import re
        pipeline_start = time.time()
        
        is_api_mode = self.llm_service.get_mode() == "api"

        if is_api_mode:
            en_input = ko_input_text
            self.logger.info("[L.U.N.A. InteractionService] API ëª¨ë“œ: ë²ˆì—­ ìƒëµ, í•œêµ­ì–´ ì…ë ¥ ê·¸ëŒ€ë¡œ ì‚¬ìš©")
        else:
            try:
                en_input = self.translator_service.translate(ko_input_text, "ko", "en")
            except Exception as e:
                self.logger.warning(f"[L.U.N.A. InteractionService] ë²ˆì—­ ì‹¤íŒ¨, ì›ë¬¸ ì‚¬ìš©: {e}")
                en_input = ko_input_text

        context_messages = self.memory_service.get_context_for_llm()
        
        messages = []
        
        messages.extend([m for m in context_messages if m.get("role") != "system"])
        
        messages.append({"role": "user", "content": en_input})
        
        mcp_tools = self._get_available_mcp_tools()

        self.logger.info(f"[L.U.N.A. InteractionService] ì‚¬ìš© ê°€ëŠ¥í•œ MCP ë„êµ¬: {len(mcp_tools)}ê°œ")
        self.logger.info(f"[L.U.N.A. InteractionService] ëŒ€í™” ë§¥ë½: {len(context_messages)}ê°œ ë©”ì‹œì§€ í¬í•¨")
        self.logger.debug(f"[L.U.N.A. InteractionService] ë„êµ¬ ëª©ë¡: {[t.get('function', {}).get('name', 'unknown') for t in mcp_tools]}")

        llm_response = self.llm_service.generate(
            target=self.llm_target,
            system_prompt=self.rp_prompt_template,
            messages=messages,
            tools=mcp_tools if mcp_tools else None,
            skip_cache=True
        )
        if not llm_response or "choices" not in llm_response:
            return self.error_response("LLM ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

        message = llm_response["choices"][0]["message"]
        response_content = message.get("content", "") or ""
        self.logger.info(f"[L.U.N.A. InteractionService] LLM ì‘ë‹µ content: {response_content[:100] if response_content else '(ë¹„ì–´ìˆìŒ)'}...")
        tool_calls, tool_end_idx = self._extract_tool_calls_from_text(response_content)
        if not tool_calls:
            tool_calls = message.get("tool_calls") or []
        self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ ë°œê²¬: {len(tool_calls)}ê°œ")

        if not tool_calls:
            auto_tool_call = self._detect_and_suggest_tool(ko_input_text, mcp_tools)
            if auto_tool_call:
                self.logger.info(f"[L.U.N.A. InteractionService] ìë™ ë„êµ¬ ê°ì§€: {auto_tool_call['function']['name']}")
                tool_calls = [auto_tool_call]

        if not tool_calls:
            cleaned = response_content or ""

            cleaned = re.sub(r'\[CONTEXT\].*', '', cleaned, flags=re.IGNORECASE | re.DOTALL)

            cleaned = re.sub(
                r'âœ“\s*[^\n]*ì‹¤í–‰ ê²°ê³¼[\s\S]*?```[\s\S]*?```',
                '',
                cleaned,
                flags=re.DOTALL
            )

            cleaned = re.sub(
                r'^\s*```[\s\S]*?```\s*',
                '',
                cleaned,
                flags=re.DOTALL
            ).strip()

            if not cleaned:
                cleaned = "ê·¸ëƒ¥ ë„¤ ìƒê° ê¸°ë‹¤ë¦¬ëŠ” ì¤‘."

            response_content = cleaned

            final_ko = response_content if is_api_mode else self.translator_service.translate(response_content, "en", "ko")
            
            try:
                self.memory_service.add_entry(
                    user_input=ko_input_text,
                    assistant_response=final_ko,
                    metadata={
                        "mode": "agent",
                        "tool_called": False,
                        "tools_used": []
                    }
                )
                self.logger.info(f"[L.U.N.A. InteractionService] ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ (ë„êµ¬ ì—†ìŒ)")
            except Exception as e:
                self.logger.warning(f"[L.U.N.A. InteractionService] ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            top_emotion = "neutral"
            style, style_weight = get_style_from_emotion(top_emotion)
            ja = self.translator_service.translate(final_ko, "ko", "ja")
            tts = self.tts_service.synthesize(text=ja, style=style, style_weight=style_weight)
            
            pipeline_elapsed = time.time() - pipeline_start
            if pipeline_elapsed > 30:
                self.logger.warning(f"[L.U.N.A. InteractionService] ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {pipeline_elapsed:.2f}s (30ì´ˆ ì´ˆê³¼ - íƒ€ì„ì•„ì›ƒ ìœ„í—˜)")
            else:
                self.logger.info(f"[L.U.N.A. InteractionService] ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {pipeline_elapsed:.2f}s")
            
            return InteractResponse(text=final_ko, emotion=top_emotion, intent="agent", style=style, audio_url=tts.get("audio_url",""))

        tool_call = tool_calls[0]
        tool_name = tool_call["function"]["name"]
        raw_args = tool_call["function"].get("arguments", {})
        if isinstance(raw_args, str):
            try:
                import json
                tool_args = json.loads(raw_args)
            except Exception:
                self.logger.warning("[L.U.N.A. InteractionService] arguments JSON íŒŒì‹± ì‹¤íŒ¨ â†’ {} ì‚¬ìš©")
                tool_args = {}
        else:
            tool_args = raw_args if isinstance(raw_args, dict) else {}

        try:
            server_id, mcp_tool_name = self._resolve_server_and_tool(tool_name, mcp_tools)
        except Exception as e:
            ack_ko = f"ë„êµ¬ ì´ë¦„ì„ í•´ì„í•˜ì§€ ëª»í–ˆì–´: {tool_name} ({e})"
            top_emotion = "neutral"
            style, style_weight = get_style_from_emotion(top_emotion)
            ja = self.translator_service.translate(ack_ko, "ko", "ja")
            tts = self.tts_service.synthesize(text=ja, style=style, style_weight=style_weight)
            return InteractResponse(text=ack_ko, emotion=top_emotion, intent="agent", style=style, audio_url=tts.get("audio_url",""))

        if not response_content:
            response_content = "ì•Œê² ì–´."
            self.logger.info(f"[L.U.N.A. InteractionService] ë¹ˆ ì‘ë‹µ â†’ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©")
        
        if tool_end_idx > 0 and tool_end_idx < len(response_content):
            response_without_tool_call = response_content[tool_end_idx:].strip()
            self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ í˜¸ì¶œ í…ìŠ¤íŠ¸ ì œê±°ë¨ (ìœ„ì¹˜: {tool_end_idx})")
        else:
            response_without_tool_call = response_content
        
        import re
        response_without_tool_call = re.sub(r'^[\}\s,]+', '', response_without_tool_call).strip()
        
        final_response = response_without_tool_call if response_without_tool_call else response_content
        
        final_ko = final_response if is_api_mode else self.translator_service.translate(final_response, "en", "ko")
        top_emotion = "neutral"
        style, style_weight = get_style_from_emotion(top_emotion)
        ja = self.translator_service.translate(final_ko, "ko", "ja")
        
        import time
        tts_start = time.time()
        self.logger.info(f"[L.U.N.A. InteractionService] ğŸ“ ìŒì„± í•©ì„± ì‹œì‘")
        
        tts = self.tts_service.synthesize(text=ja, style=style, style_weight=style_weight)
        
        tts_elapsed = time.time() - tts_start
        if tts_elapsed > 15:
            self.logger.warning(f"[L.U.N.A. InteractionService] ìŒì„± í•©ì„± ì§€ì—° ì¤‘: {tts_elapsed:.2f}s (15ì´ˆ ì´ˆê³¼)")
        else:
            self.logger.info(f"[L.U.N.A. InteractionService] ìŒì„± í•©ì„± ì™„ë£Œ: {tts_elapsed:.2f}s")
        
        try:
            self.memory_service.add_entry(
                user_input=ko_input_text,
                assistant_response=final_ko,
                metadata={
                    "mode": "agent",
                    "tool_called": len(tool_calls) > 0,
                    "tools_used": [tc["function"]["name"] for tc in tool_calls] if tool_calls else [],
                    "tool_pending_execution": True
                }
            )
            self.logger.info(f"[L.U.N.A. InteractionService] ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ (ë„êµ¬ ì‹¤í–‰ ëŒ€ê¸° ì¤‘)")
        except Exception as e:
            self.logger.warning(f"[L.U.N.A. InteractionService] ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        import asyncio # ignored
        import threading
        import time
        
        tool_result_buffer = {"result": None, "error": None}
        
        def run_tool_in_background():
            try:
                self.logger.info(f"[L.U.N.A. InteractionService] ë°±ê·¸ë¼ìš´ë“œ ë„êµ¬ ì‹¤í–‰ ì‹œì‘: {server_id}/{mcp_tool_name}")
                self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ ì¸ìˆ˜: {tool_args}")
                result = self._call_mcp_tool(server_id, mcp_tool_name, tool_args)
                self.logger.info(f"[L.U.N.A. InteractionService] ë°±ê·¸ë¼ìš´ë“œ ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ!")
                self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ ë°˜í™˜ê°’: {result[:200] if isinstance(result, str) else result}")
                
                tool_result_buffer["result"] = result
                
                try:
                    import json
                    
                    extracted_info = None
                    try:
                        result_text = result if isinstance(result, str) else str(result)

                        json_candidates = []
                        buf = []
                        depth = 0
                        for ch in result_text:
                            if ch == '{':
                                depth += 1
                            if depth > 0:
                                buf.append(ch)
                            if ch == '}':
                                depth -= 1
                                if depth == 0 and buf:
                                    cand = "".join(buf)
                                    buf = []
                                    try:
                                        obj = json.loads(cand)
                                        if isinstance(obj, dict):
                                            json_candidates.append(obj)
                                    except Exception:
                                        pass

                        target = None

                        if json_candidates:
                            candidates_with_id = [o for o in json_candidates if "id" in o]
                            if candidates_with_id:
                                target = max(candidates_with_id, key=lambda o: len(o.keys()))

                            if target is None:
                                status_like = [o for o in json_candidates if any(k in o for k in ("status", "code", "message"))]
                                if status_like:
                                    target = max(status_like, key=lambda o: len(o.keys()))

                            if target is None:
                                target = max(json_candidates, key=lambda o: len(o.keys()))

                        if target is not None:
                            extracted_info = {
                                "id": target.get("id", "N/A"),
                                "object": target.get("object", "N/A"),
                                "status": target.get("status", "N/A"),
                                "code": target.get("code", "N/A"),
                                "message": target.get("message", "N/A"),
                                "created_time": (
                                    target.get("created_time")
                                    or target.get("createdTime")
                                    or "N/A"
                                ),
                                "data": target,
                            }
                        else:
                            extracted_info = {"raw": result_text[:300]}

                    except Exception as parse_err:
                        self.logger.debug(f"[L.U.N.A. InteractionService] JSON íŒŒì‹± ì‹¤íŒ¨: {parse_err}")
                        extracted_info = {"raw": (result if isinstance(result, str) else str(result))[:300]}
                    
                    tool_result_message = (
                        f"{server_id}/{mcp_tool_name} ì‹¤í–‰ ê²°ê³¼\n"
                        f"{json.dumps(extracted_info, ensure_ascii=False, indent=2)}"
                    )

                    self.memory_service.add_entry(
                        user_input=f"[{mcp_tool_name} ë„êµ¬ ì‹¤í–‰]",
                        assistant_response=tool_result_message,
                        metadata={
                            "mode": "tool_result",
                            "tool_name": mcp_tool_name,
                            "server_id": server_id,
                            "is_tool_result": True,
                            "tool_result_info": extracted_info,
                        }
                    )
                    self.logger.info(f"[L.U.N.A. InteractionService] ë„êµ¬ ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥ ì™„ë£Œ: {extracted_info}")
                except Exception as me:
                    self.logger.warning(f"[L.U.N.A. InteractionService] ë„êµ¬ ê²°ê³¼ ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {me}")
                    
            except Exception as e:
                self.logger.error(f"[L.U.N.A. InteractionService] ë°±ê·¸ë¼ìš´ë“œ ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
                tool_result_buffer["error"] = str(e)
            finally:
                time.sleep(0.5)
        
        tool_thread = threading.Thread(target=run_tool_in_background, daemon=False)
        tool_thread.start()
        
        self.logger.info(f"[L.U.N.A. InteractionService] ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜ (ë„êµ¬ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)")
        
        pipeline_elapsed = time.time() - pipeline_start
        if pipeline_elapsed > 30:
            self.logger.warning(f"[L.U.N.A. InteractionService] ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {pipeline_elapsed:.2f}s (30ì´ˆ ì´ˆê³¼ - íƒ€ì„ì•„ì›ƒ ìœ„í—˜)")
        else:
            self.logger.info(f"[L.U.N.A. InteractionService] ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {pipeline_elapsed:.2f}s")
        
        return InteractResponse(text=final_ko, emotion=top_emotion, intent="agent", style=style, audio_url=tts.get("audio_url",""))
        
    def _run_normal_mode(self, ko_input_text: str) -> InteractResponse:
        try:
            is_api_mode = self.llm_service.get_mode() == "api"
            
            if is_api_mode:
                input_text = ko_input_text
                self.logger.info(f"[L.U.N.A. InteractionService] í•œêµ­ì–´ ì…ë ¥ ì‚¬ìš©: {input_text}")
            else:
                input_text = self.translator_service.translate(ko_input_text, "ko", "en")
                self.logger.info(f"[L.U.N.A. InteractionService] ì˜ì–´ë¡œ ë²ˆì—­: {input_text}")
            
            emotion_probs = self.emotion_service.predict(input_text)
            top_emotion = max(emotion_probs, key=emotion_probs.get) if emotion_probs else "neutral"

            context_messages = self.memory_service.get_context_for_llm()
            
            messages = [
                {"role": "system", "content": self.rp_prompt_template}
            ]
            
            messages.extend(context_messages)
            
            messages.append({"role": "user", "content": input_text})

            llm_response_dict = self.llm_service.generate(
                target=self.llm_target,
                messages=messages
            )
            response_text = llm_response_dict["choices"][0]["message"]["content"].strip()
            self.logger.info(f"LLM ì‘ë‹µ: {response_text}")

            if is_api_mode:
                ko_response = response_text
                self.logger.info(f"[L.U.N.A. InteractionService] í•œêµ­ì–´ ì‘ë‹µ ì‚¬ìš©: {ko_response}")
            else:
                ko_response = self.translator_service.translate(response_text, "en", "ko")
                self.logger.info(f"[L.U.N.A. InteractionService] í•œêµ­ì–´ë¡œ ë²ˆì—­: {ko_response}")
            
            self.memory_service.add_entry(
                user_input=ko_input_text,
                assistant_response=ko_response,
                metadata={
                    "emotion": top_emotion,
                    "intent": "general",
                    "mode": "api" if is_api_mode else "server"
                }
            )
            self.logger.info(f"[L.U.N.A. InteractionService] ëŒ€í™” ì €ì¥ ì™„ë£Œ")
            
            ja_text_for_tts = self.translator_service.translate(ko_response, "ko", "ja")
            style, style_weight = get_style_from_emotion(top_emotion)
            
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            tts_result = loop.run_until_complete(
                self.tts_service.synthesize_async(
                    text=ja_text_for_tts,
                    style=style,
                    style_weight=style_weight
                )
            )

            return InteractResponse(
                text=ko_response, emotion=top_emotion, intent="general",
                style=style, audio_url=tts_result.get("audio_url", "")
            )
        except Exception as e:
            self.logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return self.error_response("ì¼ë°˜ ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    def error_response(self, error_message: str) -> InteractResponse:
        self.logger.error(f"ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜: {error_message}")
        return InteractResponse(text=f"ì˜¤ë¥˜: {error_message}", emotion="neutral", intent="error", style="Neutral", audio_url="")
