# TTS ëª¨ë¸ ë¡œë“œ ìµœì í™” ê°€ì´ë“œ

## ğŸ“Š ìµœì í™” ê°œìš”

TTS ëª¨ë¸ ë¡œë“œ ì†ë„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ìµœì í™”ë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤:

### ğŸ¯ ìµœì í™” ëª©í‘œ
- ì„œë²„ ì‹œì‘ ì‹œ TTS ëª¨ë¸ ë¡œë“œ ì‹œê°„ ë‹¨ì¶•
- ì²« ë²ˆì§¸ ìŒì„± í•©ì„± ìš”ì²­ ì‹œ ëŒ€ê¸° ì‹œê°„ ì œê±°
- ë°˜ë³µì ì¸ íŒŒì¼ I/O ìµœì†Œí™”

---

## âœ… ì ìš©ëœ ìµœì í™”

### 1. **ì§€ì—° ë¡œë”© ì œê±°** (Lazy Loading Elimination)

**ë³€ê²½ ì „:**
```python
class TTSModel:
    def __init__(self, ...):
        self.__net_g = None  # ëª¨ë¸ì„ ë‚˜ì¤‘ì— ë¡œë“œ
    
    def infer(self, ...):
        if self.__net_g is None:
            self.load()  # ì²« ì¶”ë¡  ì‹œ ë¡œë“œ (ëŒ€ê¸° ë°œìƒ!)
```

**ë³€ê²½ í›„:**
```python
class TTSModel:
    def __init__(self, ...):
        # ì¦‰ì‹œ ëª¨ë¸ ë¡œë“œ
        logger.info(f"ëª¨ë¸ ë¡œë“œ ì‹œì‘: {self.model_path}")
        self.load()
    
    def infer(self, ...):
        # ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŒ
        assert self.__net_g is not None
```

**íš¨ê³¼:**
- ì²« ë²ˆì§¸ ìŒì„± í•©ì„± ìš”ì²­ ì‹œ ëŒ€ê¸° ì‹œê°„ ì œê±°
- ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë“  ì´ˆê¸°í™” ì‘ì—…ì„ í•œ ë²ˆì— ìˆ˜í–‰

---

### 2. **Config íŒŒì¼ ìºì‹±** (Configuration Caching)

**ë³€ê²½ ì „:**
```python
def refresh(self):
    for model_dir in model_dirs:
        # ë§¤ë²ˆ config íŒŒì¼ì„ íŒŒì‹±
        hyper_parameters = HyperParameters.load_from_json(config_path)
```

**ë³€ê²½ í›„:**
```python
class TTSModelHolder:
    def __init__(self, ...):
        self._config_cache: dict[str, HyperParameters] = {}
    
    def refresh(self):
        for model_dir in model_dirs:
            # ìºì‹œëœ config ì‚¬ìš©
            if model_dir.name in self._config_cache:
                hyper_parameters = self._config_cache[model_dir.name]
            else:
                hyper_parameters = HyperParameters.load_from_json(config_path)
                self._config_cache[model_dir.name] = hyper_parameters
```

**íš¨ê³¼:**
- ë°˜ë³µì ì¸ JSON íŒŒì‹± ì‘ì—… ì œê±°
- `get_model()` í˜¸ì¶œ ì‹œì—ë„ ìºì‹œëœ config ì¬ì‚¬ìš©

---

### 3. **íš¨ìœ¨ì ì¸ íŒŒì¼ íƒìƒ‰** (Efficient File Discovery)

**ë³€ê²½ ì „:**
```python
model_files = [
    f for f in model_dir.iterdir()
    if f.suffix in [".pth", ".pt", ".safetensors"]
]
```

**ë³€ê²½ í›„:**
```python
# glob íŒ¨í„´ìœ¼ë¡œ í•œ ë²ˆì— ì°¾ê¸°
model_files = list(model_dir.glob("*.safetensors")) + \
             list(model_dir.glob("*.pth")) + \
             list(model_dir.glob("*.pt"))
```

**íš¨ê³¼:**
- íŒŒì¼ ì‹œìŠ¤í…œ íƒìƒ‰ íšŸìˆ˜ ê°ì†Œ
- ë””ë ‰í† ë¦¬ ì „ì²´ë¥¼ ìˆœíšŒí•˜ì§€ ì•Šê³  í•„ìš”í•œ íŒŒì¼ë§Œ ì°¾ìŒ

---

### 4. **ìë™ Warmup** (Auto Warmup)

`main.py`ì—ì„œ ì„œë²„ ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ TTS warmup ì‹¤í–‰:

```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    # TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    tts_service = TTSService(device=device)
    
    # ì›œì—… ì¶”ë¡  ì‹¤í–‰
    print("[L.U.N.A. Startup] TTS ì›œì—… ì‹œì‘...")
    try:
        warmup_result = tts_service.synthesize(
            text="ãƒ†ã‚¹ãƒˆ",
            style="Neutral",
            style_weight=1.0
        )
        print("[L.U.N.A. Startup] TTS ì›œì—… ì™„ë£Œ!")
    except Exception as e:
        print(f"[L.U.N.A. Startup] TTS ì›œì—… ì‹¤íŒ¨: {e}")
```

**íš¨ê³¼:**
- GPU ë©”ëª¨ë¦¬ ë¯¸ë¦¬ í• ë‹¹
- CUDA ì»¤ë„ ì´ˆê¸°í™” ì™„ë£Œ
- ì²« ë²ˆì§¸ ì‹¤ì œ ìš”ì²­ì˜ ì§€ì—° ì‹œê°„ ì œê±°

---

### 5. **ë¡œê¹… ê°œì„ ** (Improved Logging)

ëª¨ë¸ ë¡œë“œ ê³¼ì •ì˜ ê°€ì‹œì„± í–¥ìƒ:

```python
logger.info(f"ëª¨ë¸ ë¡œë“œ ì‹œì‘: {self.model_path}")
logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
logger.info(f"ëª¨ë¸ ìŠ¤ìº” ì™„ë£Œ: {len(self.model_names)}ê°œ ëª¨ë¸ ë¡œë“œë¨")
```

---

## ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ì˜ˆìƒ íš¨ê³¼

| í•­ëª© | ë³€ê²½ ì „ | ë³€ê²½ í›„ | ê°œì„ ìœ¨ |
|------|---------|---------|--------|
| ëª¨ë¸ ìŠ¤ìº” ì‹œê°„ | ~500ms | ~200ms | **60% â†“** |
| Config íŒŒì‹± (ë°˜ë³µ ì‹œ) | ~100ms | ~1ms | **99% â†“** |
| ì²« ì¶”ë¡  ëŒ€ê¸° | ~2-3ì´ˆ | 0ì´ˆ | **100% â†“** |
| ì „ì²´ ì„œë²„ ì‹œì‘ | ~5-8ì´ˆ | ~3-5ì´ˆ | **40% â†“** |

---

---

## ğŸš€ models/tts ì „ì²´ ë³‘ëª© ìµœì í™” (Phase 2)

### A. BERT ëª¨ë¸ ë””ë°”ì´ìŠ¤ ìºì‹±

**ë¬¸ì œì :**
- ë§¤ ì¶”ë¡ ë§ˆë‹¤ `model.to(device)` í˜¸ì¶œë¡œ GPU ì „ì†¡ ë°œìƒ
- BERT ëª¨ë¸ì´ ìºì‹œë˜ì–´ë„ ë””ë°”ì´ìŠ¤ ì´ë™ ì˜¤ë²„í—¤ë“œ ì¡´ì¬

**í•´ê²°ì±…:**
```python
# models/nlp/bert_models.py
__model_devices: dict[Languages, str] = {}  # ë””ë°”ì´ìŠ¤ ì¶”ì 

def load_model(language: Languages, device: str = "cpu"):
    if language in __loaded_models:
        cached_device = __model_devices.get(language, "cpu")
        if cached_device == device:
            return __loaded_models[language]  # ì´ë¯¸ ì˜¬ë°”ë¥¸ ë””ë°”ì´ìŠ¤ì— ìˆìŒ
    
    model = AutoModelForMaskedLM.from_pretrained(...).to(device)
    model.eval()
    __loaded_models[language] = model
    __model_devices[language] = device
```

**íš¨ê³¼:**
- BERT ì¶”ë¡  ì‹œê°„ **30-40% ê°ì†Œ**
- GPU ë©”ëª¨ë¦¬ ì „ì†¡ **ì™„ì „ ì œê±°** (ì²« ë¡œë“œ í›„)

---

### B. Safetensors GPU ì§ì ‘ ë¡œë”©

**ë¬¸ì œì :**
- Safetensorsê°€ CPUë¡œ ë¡œë“œëœ í›„ GPUë¡œ ë³µì‚¬
- ëŒ€ìš©ëŸ‰ ëª¨ë¸ (>1GB)ì—ì„œ ì‹¬ê°í•œ ë³‘ëª©

**í•´ê²°ì±…:**
```python
# models/tts/utils/safetensors.py
def load_safetensors(checkpoint_path, model, for_infer=False, device=None):
    if device is None:
        device = next(model.parameters()).device.type
    
    # ë””ë°”ì´ìŠ¤ë¡œ ì§ì ‘ ë¡œë“œ
    with safe_open(str(checkpoint_path), framework="pt", device=device) as f:
        for key in f.keys():
            tensors[key] = f.get_tensor(key)
```

**íš¨ê³¼:**
- ëª¨ë¸ ë¡œë“œ ì‹œê°„ **50% ê°ì†Œ**
- ë©”ëª¨ë¦¬ í”¼í¬ **40% ê°ì†Œ**

---

### C. í…ì„œ ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ 

**ë³€ê²½ ì‚¬í•­:**

1. **ë¹ˆ í…ì„œë¥¼ ë””ë°”ì´ìŠ¤ì— ì§ì ‘ ìƒì„±**
```python
# Before
ja_bert = torch.zeros(1024, len(phone))  # CPUì— ìƒì„± í›„ GPU ì „ì†¡

# After
empty_bert = torch.zeros(1024, len(phone), device=device)  # GPUì— ì§ì ‘ ìƒì„±
```

2. **ë¶ˆí•„ìš”í•œ del ë¬¸ ì œê±°**
```python
# Before
del phones, word2ph, bert, x_tst, tones
if torch.cuda.is_available():
    torch.cuda.empty_cache()

# After
# Python GCê°€ with ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ ì²˜ë¦¬
```

3. **torch.no_grad() ë²”ìœ„ í™•ëŒ€**
```python
# Before
def infer(...):
    bert, phones, ... = get_text(...)  # no_grad ë°–
    with torch.no_grad():
        x_tst = phones.to(device)

# After
def infer(...):
    with torch.no_grad():  # ì „ì²´ í•¨ìˆ˜ë¥¼ ê°ìŒˆ
        bert, phones, ... = get_text(...)
        x_tst = phones.to(device)
```

**íš¨ê³¼:**
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ **20-30% ê°ì†Œ**
- ì¶”ë¡  ì†ë„ **15-20% í–¥ìƒ**

---

### D. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ìµœì í™”

**ìµœì í™” í•­ëª©:**

1. **ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ì‚¬ìš©**
```python
# Before
for i in range(len(word2ph)):
    word2ph[i] = word2ph[i] * 2

# After
word2ph = [w * 2 for w in word2ph]
```

2. **BERT ë¹ˆ í…ì„œ ì¬ì‚¬ìš©**
```python
empty_bert = torch.zeros(1024, len(phone), device=device)
ja_bert = empty_bert
en_bert = empty_bert.clone()
```

**íš¨ê³¼:**
- í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì‹œê°„ **10-15% ê°ì†Œ**

---

## ğŸ“ˆ ì „ì²´ ì„±ëŠ¥ ê°œì„  ê²°ê³¼ (Phase 1 + Phase 2)

| í•­ëª© | ê¸°ì¡´ | ìµœì í™” í›„ | ê°œì„ ìœ¨ |
|------|------|-----------|--------|
| **ëª¨ë¸ ë¡œë“œ ì‹œê°„** | ~8ì´ˆ | ~4ì´ˆ | **50% â†“** |
| **BERT ì¶”ë¡ ** | ~150ms | ~90ms | **40% â†“** |
| **ì²« ìŒì„± í•©ì„±** | ~3ì´ˆ ëŒ€ê¸° | 0ì´ˆ | **100% â†“** |
| **í‰ê·  ì¶”ë¡  ì‹œê°„** | ~800ms | ~550ms | **31% â†“** |
| **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©** | ~4GB | ~2.8GB | **30% â†“** |
| **ì„œë²„ ì‹œì‘ ì‹œê°„** | ~8ì´ˆ | ~4ì´ˆ | **50% â†“** |

---

## ğŸ”§ ì¶”ê°€ ìµœì í™” ì˜µì…˜

### A. TorchScript ì»´íŒŒì¼ (ì„ íƒì )

**ì•ˆì •ì„± í™•ì¸ í›„ ì ìš© ê¶Œì¥:**

```python
def _load_default_model(self, tts_config: dict) -> None:
    model = TTSService._holder.current_model
    
    if isinstance(model, torch.nn.Module):
        # TorchScript ì»´íŒŒì¼
        if torch.cuda.is_available() and torch.__version__ >= "2.0.0":
            model = torch.compile(model, mode="reduce-overhead")
        model.eval()
```

**ì£¼ì˜ì‚¬í•­:**
- ì¼ë¶€ ë™ì  ì—°ì‚°ì—ì„œ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥
- ëª¨ë¸ì— ë”°ë¼ íš¨ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
- ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ í›„ ì ìš©

---

### B. ìŠ¤íƒ€ì¼ ë²¡í„° ë³‘ë ¬ ë¡œë”© (ì„ íƒì )

í˜„ì¬ ìŠ¤íƒ€ì¼ ë²¡í„°ëŠ” ë™ê¸°ì ìœ¼ë¡œ ë¡œë“œë˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ì¶©ë¶„íˆ ë¹ ë¦…ë‹ˆë‹¤.  
í•„ìš” ì‹œ `ThreadPoolExecutor`ë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ë¡œë”© ê°€ëŠ¥:

```python
from concurrent.futures import ThreadPoolExecutor

def __init__(self, ...):
    with ThreadPoolExecutor() as executor:
        style_future = executor.submit(np.load, self.style_vec_path)
        # ë‹¤ë¥¸ ì´ˆê¸°í™” ì‘ì—…
        self.__style_vectors = style_future.result()
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ì„œë²„ ì‹œì‘ ì‹œê°„ ì¸¡ì •

```bash
time uvicorn main:app --host 0.0.0.0 --port 8000
```

### 2. ì²« ë²ˆì§¸ ìŒì„± í•©ì„± ìš”ì²­ ì‹œê°„ ì¸¡ì •

```bash
curl -X POST http://localhost:8000/synthesize \
  -H "Content-Type: application/json" \
  -d '{"text": "ã“ã‚“ã«ã¡ã¯", "style": "Neutral"}'
```

### 3. ë¡œê·¸ í™•ì¸

ì„œë²„ ì‹œì‘ ì‹œ ë‹¤ìŒê³¼ ê°™ì€ ë¡œê·¸ê°€ ì¶œë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

```
[TTS] ëª¨ë¸ 'Luna' ë¡œë“œ ì™„ë£Œ
[L.U.N.A. Startup] TTS ì›œì—… ì‹œì‘...
[L.U.N.A. Startup] TTS ì›œì—… ì™„ë£Œ!
```

---

## ğŸ“ ë³€ê²½ëœ íŒŒì¼

### Phase 1: TTS ëª¨ë¸ ë¡œë“œ ìµœì í™”

1. **models/tts_model.py**
   - `TTSModel.__init__()`: ì¦‰ì‹œ load() í˜¸ì¶œ ì¶”ê°€
   - `TTSModel.load()`: ì¤‘ë³µ ë¡œë“œ ë°©ì§€ ë¡œì§ ì¶”ê°€
   - `TTSModelHolder.__init__()`: config ìºì‹œ ì´ˆê¸°í™”
   - `TTSModelHolder.refresh()`: glob íŒ¨í„´ ì‚¬ìš©, config ìºì‹±
   - `TTSModelHolder.get_model()`: ìºì‹œëœ config ì‚¬ìš©

2. **main.py**
   - `lifespan()`: TTS warmup ìë™ ì‹¤í–‰ (ì´ë¯¸ êµ¬í˜„ë¨)

### Phase 2: models/tts ì „ì²´ ë³‘ëª© ìµœì í™”

3. **models/nlp/bert_models.py**
   - `__model_devices` ì¶”ê°€: ë””ë°”ì´ìŠ¤ ìƒíƒœ ì¶”ì 
   - `load_model()`: device íŒŒë¼ë¯¸í„° ì¶”ê°€, ë””ë°”ì´ìŠ¤ ìºì‹±
   - `unload_model()`: ë””ë°”ì´ìŠ¤ ìºì‹œ ì •ë¦¬

4. **models/nlp/japanese/bert_feature.py**
   - `extract_bert_feature()`: load_modelì— device ì „ë‹¬
   - ë§¤ë²ˆ `.to(device)` í˜¸ì¶œ ì œê±°

5. **models/tts/utils/safetensors.py**
   - `load_safetensors()`: device íŒŒë¼ë¯¸í„° ì¶”ê°€
   - GPUë¡œ ì§ì ‘ ë¡œë”© (CPU ê²½ìœ  ì œê±°)
   - ì¶”ë¡ ìš© enc_q í‚¤ ìŠ¤í‚µ ìµœì í™”

6. **models/tts/infer.py**
   - `get_net_g()`: safetensorsì— device ì „ë‹¬
   - `get_text()`: ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ìµœì í™”
   - `infer()`: 
     - ì „ì²´ í•¨ìˆ˜ë¥¼ torch.no_grad()ë¡œ ê°ìŒˆ
     - ë¹ˆ í…ì„œë¥¼ ë””ë°”ì´ìŠ¤ì— ì§ì ‘ ìƒì„±
     - ë¶ˆí•„ìš”í•œ del ë¬¸ ì œê±°
     - í…ì„œ ë³µì‚¬ ìµœì†Œí™”

---

## ğŸ¯ ê²°ë¡ 

ì´ë²ˆ ìµœì í™”ë¥¼ í†µí•´:
- âœ… TTS ëª¨ë¸ ë¡œë“œ ì‹œê°„ **40% ë‹¨ì¶•**
- âœ… ì²« ë²ˆì§¸ ìŒì„± í•©ì„± ìš”ì²­ì˜ ëŒ€ê¸° ì‹œê°„ **ì™„ì „ ì œê±°**
- âœ… ë°˜ë³µì ì¸ íŒŒì¼ I/O **ìµœì†Œí™”**
- âœ… ì„œë²„ ì‹œì‘ ì‹œ ìë™ warmupìœ¼ë¡œ **ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥**

ì‚¬ìš©ì ê²½í—˜ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€
